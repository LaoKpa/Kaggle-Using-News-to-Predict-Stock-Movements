{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\nfrom sklearn.metrics import accuracy_score\nfrom kaggle.competitions import twosigmanews","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"env = twosigmanews.make_env()\n(market_train, _) = env.get_training_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"99028b96cdb50de4bd30fa3f2ba372c2a56ec397"},"cell_type":"code","source":"cat_cols = ['assetCode']\nnum_cols = ['volume', 'close', 'open', 'returnsClosePrevRaw1', 'returnsOpenPrevRaw1', 'returnsClosePrevMktres1',\n                    'returnsOpenPrevMktres1', 'returnsClosePrevRaw10', 'returnsOpenPrevRaw10', 'returnsClosePrevMktres10',\n                    'returnsOpenPrevMktres10']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c078fe3fd4f91c448255c2362373687fda8872d"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_indices, val_indices = train_test_split(market_train.index.values,test_size=0.25, random_state=23)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ffcc22096b680ca46ab4cc80301e6745d54fd40"},"cell_type":"code","source":"def encode(encoder, x):\n    len_encoder = len(encoder)\n    try:\n        id = encoder[x]\n    except KeyError:\n        id = len_encoder\n    return id\n\nencoders = [{} for cat in cat_cols]\n\n\nfor i, cat in enumerate(cat_cols):\n    print('encoding %s ...' % cat, end=' ')\n    encoders[i] = {l: id for id, l in enumerate(market_train.loc[train_indices, cat].astype(str).unique())}\n    market_train[cat] = market_train[cat].astype(str).apply(lambda x: encode(encoders[i], x))\n    print('Done')\n\nembed_sizes = [len(encoder) + 1 for encoder in encoders] #+1 for possible unknown assets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff10b8b6643d761944eb96024408858b7641ee58"},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n \nmarket_train[num_cols] = market_train[num_cols].fillna(0)\nprint('scaling numerical columns')\n\nscaler = StandardScaler()\n\n#col_mean = market_train[col].mean()\n#market_train[col].fillna(col_mean, inplace=True)\nscaler = StandardScaler()\nmarket_train[num_cols] = scaler.fit_transform(market_train[num_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca126de46e377ae4d3d2ea6df2003b89014c44a7"},"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Input, Dense, Embedding, Concatenate, Flatten, BatchNormalization\nfrom keras.losses import binary_crossentropy, mse\n\ncategorical_inputs = []\nfor cat in cat_cols:\n    categorical_inputs.append(Input(shape=[1], name=cat))\n\ncategorical_embeddings = []\nfor i, cat in enumerate(cat_cols):\n    categorical_embeddings.append(Embedding(embed_sizes[i], 10)(categorical_inputs[i]))\n\n#categorical_logits = Concatenate()([Flatten()(cat_emb) for cat_emb in categorical_embeddings])\ncategorical_logits = Flatten()(categorical_embeddings[0])\ncategorical_logits = Dense(32,activation='relu')(categorical_logits)\n\nnumerical_inputs = Input(shape=(11,), name='num')\nnumerical_logits = numerical_inputs\nnumerical_logits = BatchNormalization()(numerical_logits)\n\nnumerical_logits = Dense(128,activation='relu')(numerical_logits)\nnumerical_logits = Dense(64,activation='relu')(numerical_logits)\n\nlogits = Concatenate()([numerical_logits,categorical_logits])\nlogits = Dense(64,activation='relu')(logits)\nout = Dense(1, activation='sigmoid')(logits)\n\nmodel = Model(inputs = categorical_inputs + [numerical_inputs], outputs=out)\nmodel.compile(optimizer='adam',loss=binary_crossentropy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d77d2e4f174a4715bee754d127b269b44c0ff065"},"cell_type":"code","source":"# Lets print our model\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c3db6823510179cae1234eb484191ce9008c9de"},"cell_type":"code","source":"def get_input(market_train, indices):\n    X_num = market_train.loc[indices, num_cols].values\n    X = {'num':X_num}\n    for cat in cat_cols:\n        X[cat] = market_train.loc[indices, cat_cols].values\n    y = (market_train.loc[indices,'returnsOpenNextMktres10'] >= 0).values\n    r = market_train.loc[indices,'returnsOpenNextMktres10'].values\n    u = market_train.loc[indices, 'universe']\n    d = market_train.loc[indices, 'time'].dt.date\n    return X,y,r,u,d\n\n# r, u and d are used to calculate the scoring metric\nX_train,y_train,r_train,u_train,d_train = get_input(market_train, train_indices)\nX_valid,y_valid,r_valid,u_valid,d_valid = get_input(market_train, val_indices)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5f2bfa68525ee79cbe84f2f31771c76a5689730"},"cell_type":"code","source":"from keras.callbacks import EarlyStopping, ModelCheckpoint\n\ncheck_point = ModelCheckpoint('model.hdf5',verbose=True, save_best_only=True)\nearly_stop = EarlyStopping(patience=5,verbose=True)\nmodel.fit(X_train,y_train.astype(int),\n          validation_data=(X_valid,y_valid.astype(int)),\n          epochs=2,\n          verbose=True,\n          callbacks=[early_stop,check_point]) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88a57c3df3e58595f627cc1d90e12f67748ac2d7"},"cell_type":"code","source":"# distribution of confidence that will be used as submission\nmodel.load_weights('model.hdf5')\nconfidence_valid = model.predict(X_valid)[:,0]*2 -1\nprint(accuracy_score(confidence_valid>0,y_valid))\nplt.hist(confidence_valid, bins='auto')\nplt.title(\"predicted confidence\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fdb56d36fd655baf6a5d038bc041e3f56ea04eea"},"cell_type":"code","source":"# calculation of actual metric that is used to calculate final score\n# r_valid_clip = r_valid.clip(-1,1) # get rid of outliers. Where do they come from??\nx_t_i = confidence_valid * r_valid * u_valid\ndata = {'day' : d_valid, 'x_t_i' : x_t_i}\ndf = pd.DataFrame(data)\nx_t = df.groupby('day').sum().values.flatten()\nmean = np.mean(x_t)\nstd = np.std(x_t)\nscore_valid = mean / std\nprint(score_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60860e261a3c7b90cc252a1d64c9f49ddbec8dad"},"cell_type":"code","source":"days = env.get_prediction_days()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71ede193492db06b8af7de81ed90d7c4ac4ef65a"},"cell_type":"code","source":"n_days = 0\nprep_time = 0\nprediction_time = 0\npackaging_time = 0\npredicted_confidences = np.array([])\nfor (market_obs_df, news_obs_df, predictions_template_df) in days:\n    n_days +=1\n    print(n_days,end=' ')\n    \n    t = time.time()\n\n    market_obs_df['assetCode_encoded'] = market_obs_df[cat].astype(str).apply(lambda x: encode(encoders[i], x))\n\n    market_obs_df[num_cols] = market_obs_df[num_cols].fillna(0)\n    market_obs_df[num_cols] = scaler.transform(market_obs_df[num_cols])\n    X_num_test = market_obs_df[num_cols].values\n    X_test = {'num':X_num_test}\n    X_test['assetCode'] = market_obs_df['assetCode_encoded'].values\n    \n    prep_time += time.time() - t\n    \n    t = time.time()\n    market_prediction = model.predict(X_test)[:,0]*2 -1\n    predicted_confidences = np.concatenate((predicted_confidences, market_prediction))\n    prediction_time += time.time() -t\n    \n    t = time.time()\n    preds = pd.DataFrame({'assetCode':market_obs_df['assetCode'],'confidence':market_prediction})\n    # insert predictions to template\n    predictions_template_df = predictions_template_df.merge(preds,how='left').drop('confidenceValue',axis=1).fillna(0).rename(columns={'confidence':'confidenceValue'})\n    env.predict(predictions_template_df)\n    packaging_time += time.time() - t\n\nenv.write_submission_file()\ntotal = prep_time + prediction_time + packaging_time\nprint(f'Preparing Data: {prep_time:.2f}s')\nprint(f'Making Predictions: {prediction_time:.2f}s')\nprint(f'Packing: {packaging_time:.2f}s')\nprint(f'Total: {total:.2f}s')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0991153eb214743860e3fe7f47f99d1b7b5c2c45"},"cell_type":"code","source":"# distribution of confidence as a sanity check: they should be distributed as above\nplt.hist(predicted_confidences, bins='auto')\nplt.title(\"predicted confidence\")\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}